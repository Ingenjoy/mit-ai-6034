9. Constraints: Visual Object Recognition. Face Recognition.
https://www.youtube.com/watch?v=gvmfbePC2pc
10.03.2017

Description: We consider how object recognition has evolved over the past 30 years. 
In alignment theory, 2-D projections are used to determine whether an additional picture is of the same object. 
To recognize faces, we use intermediate-sized features and correlation.

0. General:
- Changing of faces expressions: Interpolate between a set of images for "sad", "happy", "angry" and so on.
- History: Face recognition has been developing slowly during the past 30 years
- Functions: Any function can be approximated via rectangles. The smaller the rectangles => the more precies the approximation.
- GOLDILOCKS PRINCIPLE: Not too big, not too small. Definitive features/things should not be neither too small,  neither too big and complex.
- RUMPLESTILSKIN PRINCIPLE: The princess in the Rumpelstiltskin fairy tale who got power over Rumpelstiltskin once she learned his name. 
  Giving a name to something, whatever it may be – even if it is not the right name – allows one to expand its knowledge.
  
1. Machine vision: David Marr
- Person: David Marr (https://en.wikipedia.org/wiki/David_Marr_(neuroscientist))
- Based on neuroscience research
- Algorithm: Object recognition by David Marr
    1. Input - Primal sketch: Like in cameras, you look for edges.
    - Edges are formed from "edge fragments"
    - Form an edge-based shape of what is out there

    2. Vectors - 2.5D sketch: Decorate with vectors which show towards where the edges are oriented
    - It's 2.5D because it's actually 2D but trying to show something about the 3D arrangement of objects

    3. Convert the primals to generalized cylinders:
    - Try to match the object from 1) and 2) into an object defined with a "Genarilized cylinder"
    - Search: The actual matching process is by searching within a library of descriptions for that object

    - No one could get it to work!...

- Stages of vision (Wikipedia):
Marr described vision as proceeding from a two-dimensional visual array (on the retina) to a three-dimensional description of the world as output. His stages of vision include:

    1. a primal sketch of the scene, based on feature extraction of fundamental components of the scene, including edges, regions, etc. Note the similarity in concept to a pencil sketch drawn quickly by an artist as an impression.
    2. a 2.5D sketch of the scene, where textures are acknowledged, etc. Note the similarity in concept to the stage in drawing where an artist highlights or shades areas of a scene, to provide depth.
    3. a 3 D model, where the scene is visualised in a continuous, 3-dimensional map.
    2.5D sketch is related to stereopsis, optic flow, and motion parallax. The 2.5D sketch represents that in reality we do not see all of our surroundings but construct the viewer-centered three dimensional view of our environment. 2.5D Sketch is a paraline [clarification needed] drawing and often referred to by its generic term "axonometric" or "isometric" drawing and is often used by modern architects and designers.[

2. Alignment theories:
- Shimon Ullman (student of David Marr)
- Algorithm:
    1. Dimension pictures: Take pictures from X, Y, Z dimensions
    - Problem: some vertexes are NOT visible from these direct angles
    - You can get only an "Ortographic projection" view of the object this way

- Problem: Get an object from different perspective views and try to determine if they are the same one
    - Try to determine if the vertexes in the different objects are the same
- Assertion: Each vertex for all views can be presented as an equation
             There is only one vertex set (alpha, beta, gama...) which would make all equations work
- The points are related linearly, because they are ortographic projections
- We can generate the points in 4th view, because we already have the linear relationships in the 3 ortographic views
- Picture: These are the 2D dimensional coordinates in the drawing. This is NOT a 3D dimensional space.
- Other: For curves, you need to identify coresponding points
- Prediction: Based on Alpha, Beta, Gama and Tau we can predict the locations of points in the next view
- Features: Working from local features of objects

3. Face recognition: Shimon Ullman's next idea: Corellation theory: [32:00]
- Corellation: Take a picture of one student's face. 
  Then take a picture of the faces of the entire class together.
  Then search where it correlates the most
- But that's wouldn't work very well, because the particular student might not look like all the other ones
- Small features: Ullman's next idea was to look for small features, in stead of whole faces: pair of eyes, mouth, hair, nose and etc...
- Face recognition: You cannot recognize the entire face in it's totality. Rather, divide it to small features and try to detect them.
- GOLDILOCKS PRINCIPLE: Not too big, not too small. Definitive features/things should not be neither too small,  neither too big and complex.
- Integral: An integral can be used in order to detect if the signal of the face is matching with one from the library
  Success: If it matches, the integral (sum of the signals) will be a very high number
  Failure: If matching is low, the integral will be a quite low number

4. DEMO: FACE RECOGNITION: [42:00]
- Method used: via corellation of features (two eyes and nose)

5. Stories:
- Recongnition of complex pictures: The human mind can tell a story to the visual apparatus:
  "The cat was thirsty, so it tried to lick the dripping water with its tongue"
